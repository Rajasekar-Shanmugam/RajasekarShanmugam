{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Telecom Churn Case Study</font>\n",
    "* Submitted by:\n",
    "    1. Rajasekar Shanmugam (rajas@vmware.com)\n",
    "    2. Shijo Jacob Joshua (Joshua.shijo@gmail.com)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignoring warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import the required library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "pd.set_option('display.max_columns',230)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1 : Data understanding, preparation, feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data understanding\n",
    "All important data quality checks are performed and inconsistent/missing data is handled appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99999, 226)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99999 entries, 0 to 99998\n",
      "Columns: 226 entries, mobile_number to sep_vbc_3g\n",
      "dtypes: float64(179), int64(35), object(12)\n",
      "memory usage: 172.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mobile_number</th>\n",
       "      <th>circle_id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>last_date_of_month_6</th>\n",
       "      <th>last_date_of_month_7</th>\n",
       "      <th>last_date_of_month_8</th>\n",
       "      <th>last_date_of_month_9</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>arpu_9</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>onnet_mou_9</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>offnet_mou_9</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>roam_ic_mou_7</th>\n",
       "      <th>roam_ic_mou_8</th>\n",
       "      <th>roam_ic_mou_9</th>\n",
       "      <th>roam_og_mou_6</th>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <th>roam_og_mou_9</th>\n",
       "      <th>loc_og_t2t_mou_6</th>\n",
       "      <th>loc_og_t2t_mou_7</th>\n",
       "      <th>loc_og_t2t_mou_8</th>\n",
       "      <th>loc_og_t2t_mou_9</th>\n",
       "      <th>loc_og_t2m_mou_6</th>\n",
       "      <th>loc_og_t2m_mou_7</th>\n",
       "      <th>loc_og_t2m_mou_8</th>\n",
       "      <th>loc_og_t2m_mou_9</th>\n",
       "      <th>loc_og_t2f_mou_6</th>\n",
       "      <th>loc_og_t2f_mou_7</th>\n",
       "      <th>loc_og_t2f_mou_8</th>\n",
       "      <th>loc_og_t2f_mou_9</th>\n",
       "      <th>loc_og_t2c_mou_6</th>\n",
       "      <th>loc_og_t2c_mou_7</th>\n",
       "      <th>loc_og_t2c_mou_8</th>\n",
       "      <th>loc_og_t2c_mou_9</th>\n",
       "      <th>loc_og_mou_6</th>\n",
       "      <th>loc_og_mou_7</th>\n",
       "      <th>loc_og_mou_8</th>\n",
       "      <th>loc_og_mou_9</th>\n",
       "      <th>std_og_t2t_mou_6</th>\n",
       "      <th>std_og_t2t_mou_7</th>\n",
       "      <th>std_og_t2t_mou_8</th>\n",
       "      <th>std_og_t2t_mou_9</th>\n",
       "      <th>std_og_t2m_mou_6</th>\n",
       "      <th>std_og_t2m_mou_7</th>\n",
       "      <th>std_og_t2m_mou_8</th>\n",
       "      <th>std_og_t2m_mou_9</th>\n",
       "      <th>std_og_t2f_mou_6</th>\n",
       "      <th>std_og_t2f_mou_7</th>\n",
       "      <th>std_og_t2f_mou_8</th>\n",
       "      <th>std_og_t2f_mou_9</th>\n",
       "      <th>std_og_t2c_mou_6</th>\n",
       "      <th>std_og_t2c_mou_7</th>\n",
       "      <th>std_og_t2c_mou_8</th>\n",
       "      <th>std_og_t2c_mou_9</th>\n",
       "      <th>std_og_mou_6</th>\n",
       "      <th>std_og_mou_7</th>\n",
       "      <th>std_og_mou_8</th>\n",
       "      <th>std_og_mou_9</th>\n",
       "      <th>isd_og_mou_6</th>\n",
       "      <th>isd_og_mou_7</th>\n",
       "      <th>isd_og_mou_8</th>\n",
       "      <th>isd_og_mou_9</th>\n",
       "      <th>spl_og_mou_6</th>\n",
       "      <th>spl_og_mou_7</th>\n",
       "      <th>spl_og_mou_8</th>\n",
       "      <th>spl_og_mou_9</th>\n",
       "      <th>og_others_6</th>\n",
       "      <th>og_others_7</th>\n",
       "      <th>og_others_8</th>\n",
       "      <th>og_others_9</th>\n",
       "      <th>total_og_mou_6</th>\n",
       "      <th>total_og_mou_7</th>\n",
       "      <th>total_og_mou_8</th>\n",
       "      <th>total_og_mou_9</th>\n",
       "      <th>loc_ic_t2t_mou_6</th>\n",
       "      <th>loc_ic_t2t_mou_7</th>\n",
       "      <th>loc_ic_t2t_mou_8</th>\n",
       "      <th>loc_ic_t2t_mou_9</th>\n",
       "      <th>loc_ic_t2m_mou_6</th>\n",
       "      <th>loc_ic_t2m_mou_7</th>\n",
       "      <th>loc_ic_t2m_mou_8</th>\n",
       "      <th>loc_ic_t2m_mou_9</th>\n",
       "      <th>loc_ic_t2f_mou_6</th>\n",
       "      <th>loc_ic_t2f_mou_7</th>\n",
       "      <th>loc_ic_t2f_mou_8</th>\n",
       "      <th>loc_ic_t2f_mou_9</th>\n",
       "      <th>loc_ic_mou_6</th>\n",
       "      <th>loc_ic_mou_7</th>\n",
       "      <th>loc_ic_mou_8</th>\n",
       "      <th>loc_ic_mou_9</th>\n",
       "      <th>std_ic_t2t_mou_6</th>\n",
       "      <th>std_ic_t2t_mou_7</th>\n",
       "      <th>std_ic_t2t_mou_8</th>\n",
       "      <th>std_ic_t2t_mou_9</th>\n",
       "      <th>std_ic_t2m_mou_6</th>\n",
       "      <th>std_ic_t2m_mou_7</th>\n",
       "      <th>std_ic_t2m_mou_8</th>\n",
       "      <th>std_ic_t2m_mou_9</th>\n",
       "      <th>std_ic_t2f_mou_6</th>\n",
       "      <th>std_ic_t2f_mou_7</th>\n",
       "      <th>std_ic_t2f_mou_8</th>\n",
       "      <th>std_ic_t2f_mou_9</th>\n",
       "      <th>std_ic_t2o_mou_6</th>\n",
       "      <th>std_ic_t2o_mou_7</th>\n",
       "      <th>std_ic_t2o_mou_8</th>\n",
       "      <th>std_ic_t2o_mou_9</th>\n",
       "      <th>std_ic_mou_6</th>\n",
       "      <th>std_ic_mou_7</th>\n",
       "      <th>std_ic_mou_8</th>\n",
       "      <th>std_ic_mou_9</th>\n",
       "      <th>total_ic_mou_6</th>\n",
       "      <th>total_ic_mou_7</th>\n",
       "      <th>total_ic_mou_8</th>\n",
       "      <th>total_ic_mou_9</th>\n",
       "      <th>spl_ic_mou_6</th>\n",
       "      <th>spl_ic_mou_7</th>\n",
       "      <th>spl_ic_mou_8</th>\n",
       "      <th>spl_ic_mou_9</th>\n",
       "      <th>isd_ic_mou_6</th>\n",
       "      <th>isd_ic_mou_7</th>\n",
       "      <th>isd_ic_mou_8</th>\n",
       "      <th>isd_ic_mou_9</th>\n",
       "      <th>ic_others_6</th>\n",
       "      <th>ic_others_7</th>\n",
       "      <th>ic_others_8</th>\n",
       "      <th>ic_others_9</th>\n",
       "      <th>total_rech_num_6</th>\n",
       "      <th>total_rech_num_7</th>\n",
       "      <th>total_rech_num_8</th>\n",
       "      <th>total_rech_num_9</th>\n",
       "      <th>total_rech_amt_6</th>\n",
       "      <th>total_rech_amt_7</th>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <th>total_rech_amt_9</th>\n",
       "      <th>max_rech_amt_6</th>\n",
       "      <th>max_rech_amt_7</th>\n",
       "      <th>max_rech_amt_8</th>\n",
       "      <th>max_rech_amt_9</th>\n",
       "      <th>date_of_last_rech_6</th>\n",
       "      <th>date_of_last_rech_7</th>\n",
       "      <th>date_of_last_rech_8</th>\n",
       "      <th>date_of_last_rech_9</th>\n",
       "      <th>last_day_rch_amt_6</th>\n",
       "      <th>last_day_rch_amt_7</th>\n",
       "      <th>last_day_rch_amt_8</th>\n",
       "      <th>last_day_rch_amt_9</th>\n",
       "      <th>date_of_last_rech_data_6</th>\n",
       "      <th>date_of_last_rech_data_7</th>\n",
       "      <th>date_of_last_rech_data_8</th>\n",
       "      <th>date_of_last_rech_data_9</th>\n",
       "      <th>total_rech_data_6</th>\n",
       "      <th>total_rech_data_7</th>\n",
       "      <th>total_rech_data_8</th>\n",
       "      <th>total_rech_data_9</th>\n",
       "      <th>max_rech_data_6</th>\n",
       "      <th>max_rech_data_7</th>\n",
       "      <th>max_rech_data_8</th>\n",
       "      <th>max_rech_data_9</th>\n",
       "      <th>count_rech_2g_6</th>\n",
       "      <th>count_rech_2g_7</th>\n",
       "      <th>count_rech_2g_8</th>\n",
       "      <th>count_rech_2g_9</th>\n",
       "      <th>count_rech_3g_6</th>\n",
       "      <th>count_rech_3g_7</th>\n",
       "      <th>count_rech_3g_8</th>\n",
       "      <th>count_rech_3g_9</th>\n",
       "      <th>av_rech_amt_data_6</th>\n",
       "      <th>av_rech_amt_data_7</th>\n",
       "      <th>av_rech_amt_data_8</th>\n",
       "      <th>av_rech_amt_data_9</th>\n",
       "      <th>vol_2g_mb_6</th>\n",
       "      <th>vol_2g_mb_7</th>\n",
       "      <th>vol_2g_mb_8</th>\n",
       "      <th>vol_2g_mb_9</th>\n",
       "      <th>vol_3g_mb_6</th>\n",
       "      <th>vol_3g_mb_7</th>\n",
       "      <th>vol_3g_mb_8</th>\n",
       "      <th>vol_3g_mb_9</th>\n",
       "      <th>arpu_3g_6</th>\n",
       "      <th>arpu_3g_7</th>\n",
       "      <th>arpu_3g_8</th>\n",
       "      <th>arpu_3g_9</th>\n",
       "      <th>arpu_2g_6</th>\n",
       "      <th>arpu_2g_7</th>\n",
       "      <th>arpu_2g_8</th>\n",
       "      <th>arpu_2g_9</th>\n",
       "      <th>night_pck_user_6</th>\n",
       "      <th>night_pck_user_7</th>\n",
       "      <th>night_pck_user_8</th>\n",
       "      <th>night_pck_user_9</th>\n",
       "      <th>monthly_2g_6</th>\n",
       "      <th>monthly_2g_7</th>\n",
       "      <th>monthly_2g_8</th>\n",
       "      <th>monthly_2g_9</th>\n",
       "      <th>sachet_2g_6</th>\n",
       "      <th>sachet_2g_7</th>\n",
       "      <th>sachet_2g_8</th>\n",
       "      <th>sachet_2g_9</th>\n",
       "      <th>monthly_3g_6</th>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <th>monthly_3g_9</th>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>sachet_3g_9</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>fb_user_9</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>sep_vbc_3g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000842753</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>197.385</td>\n",
       "      <td>214.816</td>\n",
       "      <td>213.803</td>\n",
       "      <td>21.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>362</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>6/21/2014</td>\n",
       "      <td>7/16/2014</td>\n",
       "      <td>8/8/2014</td>\n",
       "      <td>9/28/2014</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>6/21/2014</td>\n",
       "      <td>7/16/2014</td>\n",
       "      <td>8/8/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>252.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>252.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.13</td>\n",
       "      <td>1.32</td>\n",
       "      <td>5.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.57</td>\n",
       "      <td>150.76</td>\n",
       "      <td>109.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>212.17</td>\n",
       "      <td>212.17</td>\n",
       "      <td>212.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>212.17</td>\n",
       "      <td>212.17</td>\n",
       "      <td>212.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>968</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.20</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7001865778</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>34.047</td>\n",
       "      <td>355.074</td>\n",
       "      <td>268.321</td>\n",
       "      <td>86.285</td>\n",
       "      <td>24.11</td>\n",
       "      <td>78.68</td>\n",
       "      <td>7.68</td>\n",
       "      <td>18.34</td>\n",
       "      <td>15.74</td>\n",
       "      <td>99.84</td>\n",
       "      <td>304.76</td>\n",
       "      <td>53.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23.88</td>\n",
       "      <td>74.56</td>\n",
       "      <td>7.68</td>\n",
       "      <td>18.34</td>\n",
       "      <td>11.51</td>\n",
       "      <td>75.94</td>\n",
       "      <td>291.86</td>\n",
       "      <td>53.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35.39</td>\n",
       "      <td>150.51</td>\n",
       "      <td>299.54</td>\n",
       "      <td>72.11</td>\n",
       "      <td>0.23</td>\n",
       "      <td>4.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>4.58</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.68</td>\n",
       "      <td>23.43</td>\n",
       "      <td>12.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.31</td>\n",
       "      <td>178.53</td>\n",
       "      <td>312.44</td>\n",
       "      <td>72.11</td>\n",
       "      <td>1.61</td>\n",
       "      <td>29.91</td>\n",
       "      <td>29.23</td>\n",
       "      <td>116.09</td>\n",
       "      <td>17.48</td>\n",
       "      <td>65.38</td>\n",
       "      <td>375.58</td>\n",
       "      <td>56.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.93</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.09</td>\n",
       "      <td>104.23</td>\n",
       "      <td>408.43</td>\n",
       "      <td>173.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.49</td>\n",
       "      <td>15.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.84</td>\n",
       "      <td>15.01</td>\n",
       "      <td>26.83</td>\n",
       "      <td>104.23</td>\n",
       "      <td>423.28</td>\n",
       "      <td>188.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>74</td>\n",
       "      <td>384</td>\n",
       "      <td>283</td>\n",
       "      <td>121</td>\n",
       "      <td>44</td>\n",
       "      <td>154</td>\n",
       "      <td>65</td>\n",
       "      <td>50</td>\n",
       "      <td>6/29/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/28/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>44</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7/25/2014</td>\n",
       "      <td>8/10/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>108.07</td>\n",
       "      <td>365.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.61</td>\n",
       "      <td>7.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7001625959</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>167.690</td>\n",
       "      <td>189.058</td>\n",
       "      <td>210.226</td>\n",
       "      <td>290.714</td>\n",
       "      <td>11.54</td>\n",
       "      <td>55.24</td>\n",
       "      <td>37.26</td>\n",
       "      <td>74.81</td>\n",
       "      <td>143.33</td>\n",
       "      <td>220.59</td>\n",
       "      <td>208.36</td>\n",
       "      <td>118.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>70.94</td>\n",
       "      <td>7.19</td>\n",
       "      <td>28.74</td>\n",
       "      <td>13.58</td>\n",
       "      <td>14.39</td>\n",
       "      <td>29.34</td>\n",
       "      <td>16.86</td>\n",
       "      <td>38.46</td>\n",
       "      <td>28.16</td>\n",
       "      <td>24.11</td>\n",
       "      <td>21.79</td>\n",
       "      <td>15.61</td>\n",
       "      <td>22.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.54</td>\n",
       "      <td>45.76</td>\n",
       "      <td>0.48</td>\n",
       "      <td>60.66</td>\n",
       "      <td>67.41</td>\n",
       "      <td>67.66</td>\n",
       "      <td>64.81</td>\n",
       "      <td>4.34</td>\n",
       "      <td>26.49</td>\n",
       "      <td>22.58</td>\n",
       "      <td>8.76</td>\n",
       "      <td>41.81</td>\n",
       "      <td>67.41</td>\n",
       "      <td>75.53</td>\n",
       "      <td>9.28</td>\n",
       "      <td>1.48</td>\n",
       "      <td>14.76</td>\n",
       "      <td>22.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.64</td>\n",
       "      <td>108.68</td>\n",
       "      <td>120.94</td>\n",
       "      <td>18.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.56</td>\n",
       "      <td>236.84</td>\n",
       "      <td>96.84</td>\n",
       "      <td>42.08</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155.33</td>\n",
       "      <td>412.94</td>\n",
       "      <td>285.46</td>\n",
       "      <td>124.94</td>\n",
       "      <td>115.69</td>\n",
       "      <td>71.11</td>\n",
       "      <td>67.46</td>\n",
       "      <td>148.23</td>\n",
       "      <td>14.38</td>\n",
       "      <td>15.44</td>\n",
       "      <td>38.89</td>\n",
       "      <td>38.98</td>\n",
       "      <td>99.48</td>\n",
       "      <td>122.29</td>\n",
       "      <td>49.63</td>\n",
       "      <td>158.19</td>\n",
       "      <td>229.56</td>\n",
       "      <td>208.86</td>\n",
       "      <td>155.99</td>\n",
       "      <td>345.41</td>\n",
       "      <td>72.41</td>\n",
       "      <td>71.29</td>\n",
       "      <td>28.69</td>\n",
       "      <td>49.44</td>\n",
       "      <td>45.18</td>\n",
       "      <td>177.01</td>\n",
       "      <td>167.09</td>\n",
       "      <td>118.18</td>\n",
       "      <td>21.73</td>\n",
       "      <td>58.34</td>\n",
       "      <td>43.23</td>\n",
       "      <td>3.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.33</td>\n",
       "      <td>306.66</td>\n",
       "      <td>239.03</td>\n",
       "      <td>171.49</td>\n",
       "      <td>370.04</td>\n",
       "      <td>519.53</td>\n",
       "      <td>395.03</td>\n",
       "      <td>517.74</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>168</td>\n",
       "      <td>315</td>\n",
       "      <td>116</td>\n",
       "      <td>358</td>\n",
       "      <td>86</td>\n",
       "      <td>200</td>\n",
       "      <td>86</td>\n",
       "      <td>100</td>\n",
       "      <td>6/17/2014</td>\n",
       "      <td>7/24/2014</td>\n",
       "      <td>8/14/2014</td>\n",
       "      <td>9/29/2014</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9/17/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7001204172</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>221.338</td>\n",
       "      <td>251.102</td>\n",
       "      <td>508.054</td>\n",
       "      <td>389.500</td>\n",
       "      <td>99.91</td>\n",
       "      <td>54.39</td>\n",
       "      <td>310.98</td>\n",
       "      <td>241.71</td>\n",
       "      <td>123.31</td>\n",
       "      <td>109.01</td>\n",
       "      <td>71.68</td>\n",
       "      <td>113.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.86</td>\n",
       "      <td>44.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.09</td>\n",
       "      <td>39.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>73.68</td>\n",
       "      <td>34.81</td>\n",
       "      <td>10.61</td>\n",
       "      <td>15.49</td>\n",
       "      <td>107.43</td>\n",
       "      <td>83.21</td>\n",
       "      <td>22.46</td>\n",
       "      <td>65.46</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4.91</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>183.03</td>\n",
       "      <td>118.68</td>\n",
       "      <td>37.99</td>\n",
       "      <td>83.03</td>\n",
       "      <td>26.23</td>\n",
       "      <td>14.89</td>\n",
       "      <td>289.58</td>\n",
       "      <td>226.21</td>\n",
       "      <td>2.99</td>\n",
       "      <td>1.73</td>\n",
       "      <td>6.53</td>\n",
       "      <td>9.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.23</td>\n",
       "      <td>16.63</td>\n",
       "      <td>296.11</td>\n",
       "      <td>236.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.09</td>\n",
       "      <td>43.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>223.23</td>\n",
       "      <td>135.31</td>\n",
       "      <td>352.21</td>\n",
       "      <td>362.54</td>\n",
       "      <td>62.08</td>\n",
       "      <td>19.98</td>\n",
       "      <td>8.04</td>\n",
       "      <td>41.73</td>\n",
       "      <td>113.96</td>\n",
       "      <td>64.51</td>\n",
       "      <td>20.28</td>\n",
       "      <td>52.86</td>\n",
       "      <td>57.43</td>\n",
       "      <td>27.09</td>\n",
       "      <td>19.84</td>\n",
       "      <td>65.59</td>\n",
       "      <td>233.48</td>\n",
       "      <td>111.59</td>\n",
       "      <td>48.18</td>\n",
       "      <td>160.19</td>\n",
       "      <td>43.48</td>\n",
       "      <td>66.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>129.84</td>\n",
       "      <td>1.33</td>\n",
       "      <td>38.56</td>\n",
       "      <td>4.94</td>\n",
       "      <td>13.98</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.99</td>\n",
       "      <td>105.01</td>\n",
       "      <td>4.94</td>\n",
       "      <td>143.83</td>\n",
       "      <td>280.08</td>\n",
       "      <td>216.61</td>\n",
       "      <td>53.13</td>\n",
       "      <td>305.38</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>230</td>\n",
       "      <td>310</td>\n",
       "      <td>601</td>\n",
       "      <td>410</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>6/28/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7000142493</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>261.636</td>\n",
       "      <td>309.876</td>\n",
       "      <td>238.174</td>\n",
       "      <td>163.426</td>\n",
       "      <td>50.31</td>\n",
       "      <td>149.44</td>\n",
       "      <td>83.89</td>\n",
       "      <td>58.78</td>\n",
       "      <td>76.96</td>\n",
       "      <td>91.88</td>\n",
       "      <td>124.26</td>\n",
       "      <td>45.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.31</td>\n",
       "      <td>149.44</td>\n",
       "      <td>83.89</td>\n",
       "      <td>58.78</td>\n",
       "      <td>67.64</td>\n",
       "      <td>91.88</td>\n",
       "      <td>124.26</td>\n",
       "      <td>37.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>117.96</td>\n",
       "      <td>241.33</td>\n",
       "      <td>208.16</td>\n",
       "      <td>98.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.28</td>\n",
       "      <td>241.33</td>\n",
       "      <td>208.16</td>\n",
       "      <td>104.59</td>\n",
       "      <td>105.68</td>\n",
       "      <td>88.49</td>\n",
       "      <td>233.81</td>\n",
       "      <td>154.56</td>\n",
       "      <td>106.84</td>\n",
       "      <td>109.54</td>\n",
       "      <td>104.13</td>\n",
       "      <td>48.24</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>214.03</td>\n",
       "      <td>198.04</td>\n",
       "      <td>337.94</td>\n",
       "      <td>202.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>2.31</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.86</td>\n",
       "      <td>2.31</td>\n",
       "      <td>216.44</td>\n",
       "      <td>198.29</td>\n",
       "      <td>338.81</td>\n",
       "      <td>205.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>196</td>\n",
       "      <td>350</td>\n",
       "      <td>287</td>\n",
       "      <td>200</td>\n",
       "      <td>56</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>6/26/2014</td>\n",
       "      <td>7/28/2014</td>\n",
       "      <td>8/9/2014</td>\n",
       "      <td>9/28/2014</td>\n",
       "      <td>50</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>6/4/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mobile_number  circle_id  loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou  \\\n",
       "0     7000842753        109             0.0             0.0             0.0   \n",
       "1     7001865778        109             0.0             0.0             0.0   \n",
       "2     7001625959        109             0.0             0.0             0.0   \n",
       "3     7001204172        109             0.0             0.0             0.0   \n",
       "4     7000142493        109             0.0             0.0             0.0   \n",
       "\n",
       "  last_date_of_month_6 last_date_of_month_7 last_date_of_month_8  \\\n",
       "0            6/30/2014            7/31/2014            8/31/2014   \n",
       "1            6/30/2014            7/31/2014            8/31/2014   \n",
       "2            6/30/2014            7/31/2014            8/31/2014   \n",
       "3            6/30/2014            7/31/2014            8/31/2014   \n",
       "4            6/30/2014            7/31/2014            8/31/2014   \n",
       "\n",
       "  last_date_of_month_9   arpu_6   arpu_7   arpu_8   arpu_9  onnet_mou_6  \\\n",
       "0            9/30/2014  197.385  214.816  213.803   21.100          NaN   \n",
       "1            9/30/2014   34.047  355.074  268.321   86.285        24.11   \n",
       "2            9/30/2014  167.690  189.058  210.226  290.714        11.54   \n",
       "3            9/30/2014  221.338  251.102  508.054  389.500        99.91   \n",
       "4            9/30/2014  261.636  309.876  238.174  163.426        50.31   \n",
       "\n",
       "   onnet_mou_7  onnet_mou_8  onnet_mou_9  offnet_mou_6  offnet_mou_7  \\\n",
       "0          NaN         0.00          NaN           NaN           NaN   \n",
       "1        78.68         7.68        18.34         15.74         99.84   \n",
       "2        55.24        37.26        74.81        143.33        220.59   \n",
       "3        54.39       310.98       241.71        123.31        109.01   \n",
       "4       149.44        83.89        58.78         76.96         91.88   \n",
       "\n",
       "   offnet_mou_8  offnet_mou_9  roam_ic_mou_6  roam_ic_mou_7  roam_ic_mou_8  \\\n",
       "0          0.00           NaN            NaN            NaN           0.00   \n",
       "1        304.76         53.76            0.0           0.00           0.00   \n",
       "2        208.36        118.91            0.0           0.00           0.00   \n",
       "3         71.68        113.54            0.0          54.86          44.38   \n",
       "4        124.26         45.81            0.0           0.00           0.00   \n",
       "\n",
       "   roam_ic_mou_9  roam_og_mou_6  roam_og_mou_7  roam_og_mou_8  roam_og_mou_9  \\\n",
       "0            NaN            NaN            NaN           0.00            NaN   \n",
       "1           0.00            0.0           0.00           0.00           0.00   \n",
       "2          38.49            0.0           0.00           0.00          70.94   \n",
       "3           0.00            0.0          28.09          39.04           0.00   \n",
       "4           0.00            0.0           0.00           0.00           0.00   \n",
       "\n",
       "   loc_og_t2t_mou_6  loc_og_t2t_mou_7  loc_og_t2t_mou_8  loc_og_t2t_mou_9  \\\n",
       "0               NaN               NaN              0.00               NaN   \n",
       "1             23.88             74.56              7.68             18.34   \n",
       "2              7.19             28.74             13.58             14.39   \n",
       "3             73.68             34.81             10.61             15.49   \n",
       "4             50.31            149.44             83.89             58.78   \n",
       "\n",
       "   loc_og_t2m_mou_6  loc_og_t2m_mou_7  loc_og_t2m_mou_8  loc_og_t2m_mou_9  \\\n",
       "0               NaN               NaN              0.00               NaN   \n",
       "1             11.51             75.94            291.86             53.76   \n",
       "2             29.34             16.86             38.46             28.16   \n",
       "3            107.43             83.21             22.46             65.46   \n",
       "4             67.64             91.88            124.26             37.89   \n",
       "\n",
       "   loc_og_t2f_mou_6  loc_og_t2f_mou_7  loc_og_t2f_mou_8  loc_og_t2f_mou_9  \\\n",
       "0               NaN               NaN              0.00               NaN   \n",
       "1              0.00              0.00              0.00              0.00   \n",
       "2             24.11             21.79             15.61             22.24   \n",
       "3              1.91              0.65              4.91              2.06   \n",
       "4              0.00              0.00              0.00              1.93   \n",
       "\n",
       "   loc_og_t2c_mou_6  loc_og_t2c_mou_7  loc_og_t2c_mou_8  loc_og_t2c_mou_9  \\\n",
       "0               NaN               NaN              0.00               NaN   \n",
       "1               0.0              2.91              0.00              0.00   \n",
       "2               0.0            135.54             45.76              0.48   \n",
       "3               0.0              0.00              0.00              0.00   \n",
       "4               0.0              0.00              0.00              0.00   \n",
       "\n",
       "   loc_og_mou_6  loc_og_mou_7  loc_og_mou_8  loc_og_mou_9  std_og_t2t_mou_6  \\\n",
       "0           NaN           NaN          0.00           NaN               NaN   \n",
       "1         35.39        150.51        299.54         72.11              0.23   \n",
       "2         60.66         67.41         67.66         64.81              4.34   \n",
       "3        183.03        118.68         37.99         83.03             26.23   \n",
       "4        117.96        241.33        208.16         98.61              0.00   \n",
       "\n",
       "   std_og_t2t_mou_7  std_og_t2t_mou_8  std_og_t2t_mou_9  std_og_t2m_mou_6  \\\n",
       "0               NaN              0.00               NaN               NaN   \n",
       "1              4.11              0.00              0.00              0.00   \n",
       "2             26.49             22.58              8.76             41.81   \n",
       "3             14.89            289.58            226.21              2.99   \n",
       "4              0.00              0.00              0.00              9.31   \n",
       "\n",
       "   std_og_t2m_mou_7  std_og_t2m_mou_8  std_og_t2m_mou_9  std_og_t2f_mou_6  \\\n",
       "0               NaN              0.00               NaN               NaN   \n",
       "1              0.46              0.13              0.00              0.00   \n",
       "2             67.41             75.53              9.28              1.48   \n",
       "3              1.73              6.53              9.99              0.00   \n",
       "4              0.00              0.00              0.00              0.00   \n",
       "\n",
       "   std_og_t2f_mou_7  std_og_t2f_mou_8  std_og_t2f_mou_9  std_og_t2c_mou_6  \\\n",
       "0               NaN              0.00               NaN               NaN   \n",
       "1              0.00              0.00               0.0               0.0   \n",
       "2             14.76             22.83               0.0               0.0   \n",
       "3              0.00              0.00               0.0               0.0   \n",
       "4              0.00              0.00               0.0               0.0   \n",
       "\n",
       "   std_og_t2c_mou_7  std_og_t2c_mou_8  std_og_t2c_mou_9  std_og_mou_6  \\\n",
       "0               NaN               0.0               NaN           NaN   \n",
       "1               0.0               0.0               0.0          0.23   \n",
       "2               0.0               0.0               0.0         47.64   \n",
       "3               0.0               0.0               0.0         29.23   \n",
       "4               0.0               0.0               0.0          9.31   \n",
       "\n",
       "   std_og_mou_7  std_og_mou_8  std_og_mou_9  isd_og_mou_6  isd_og_mou_7  \\\n",
       "0           NaN          0.00           NaN           NaN           NaN   \n",
       "1          4.58          0.13          0.00           0.0           0.0   \n",
       "2        108.68        120.94         18.04           0.0           0.0   \n",
       "3         16.63        296.11        236.21           0.0           0.0   \n",
       "4          0.00          0.00          0.00           0.0           0.0   \n",
       "\n",
       "   isd_og_mou_8  isd_og_mou_9  spl_og_mou_6  spl_og_mou_7  spl_og_mou_8  \\\n",
       "0           0.0           NaN           NaN           NaN          0.00   \n",
       "1           0.0           0.0          4.68         23.43         12.76   \n",
       "2           0.0           0.0         46.56        236.84         96.84   \n",
       "3           0.0           0.0         10.96          0.00         18.09   \n",
       "4           0.0           0.0          0.00          0.00          0.00   \n",
       "\n",
       "   spl_og_mou_9  og_others_6  og_others_7  og_others_8  og_others_9  \\\n",
       "0           NaN          NaN          NaN          0.0          NaN   \n",
       "1          0.00         0.00          0.0          0.0          0.0   \n",
       "2         42.08         0.45          0.0          0.0          0.0   \n",
       "3         43.29         0.00          0.0          0.0          0.0   \n",
       "4          5.98         0.00          0.0          0.0          0.0   \n",
       "\n",
       "   total_og_mou_6  total_og_mou_7  total_og_mou_8  total_og_mou_9  \\\n",
       "0            0.00            0.00            0.00            0.00   \n",
       "1           40.31          178.53          312.44           72.11   \n",
       "2          155.33          412.94          285.46          124.94   \n",
       "3          223.23          135.31          352.21          362.54   \n",
       "4          127.28          241.33          208.16          104.59   \n",
       "\n",
       "   loc_ic_t2t_mou_6  loc_ic_t2t_mou_7  loc_ic_t2t_mou_8  loc_ic_t2t_mou_9  \\\n",
       "0               NaN               NaN              0.16               NaN   \n",
       "1              1.61             29.91             29.23            116.09   \n",
       "2            115.69             71.11             67.46            148.23   \n",
       "3             62.08             19.98              8.04             41.73   \n",
       "4            105.68             88.49            233.81            154.56   \n",
       "\n",
       "   loc_ic_t2m_mou_6  loc_ic_t2m_mou_7  loc_ic_t2m_mou_8  loc_ic_t2m_mou_9  \\\n",
       "0               NaN               NaN              4.13               NaN   \n",
       "1             17.48             65.38            375.58             56.93   \n",
       "2             14.38             15.44             38.89             38.98   \n",
       "3            113.96             64.51             20.28             52.86   \n",
       "4            106.84            109.54            104.13             48.24   \n",
       "\n",
       "   loc_ic_t2f_mou_6  loc_ic_t2f_mou_7  loc_ic_t2f_mou_8  loc_ic_t2f_mou_9  \\\n",
       "0               NaN               NaN              1.15               NaN   \n",
       "1              0.00              8.93              3.61              0.00   \n",
       "2             99.48            122.29             49.63            158.19   \n",
       "3             57.43             27.09             19.84             65.59   \n",
       "4              1.50              0.00              0.00              0.00   \n",
       "\n",
       "   loc_ic_mou_6  loc_ic_mou_7  loc_ic_mou_8  loc_ic_mou_9  std_ic_t2t_mou_6  \\\n",
       "0           NaN           NaN          5.44           NaN               NaN   \n",
       "1         19.09        104.23        408.43        173.03              0.00   \n",
       "2        229.56        208.86        155.99        345.41             72.41   \n",
       "3        233.48        111.59         48.18        160.19             43.48   \n",
       "4        214.03        198.04        337.94        202.81              0.00   \n",
       "\n",
       "   std_ic_t2t_mou_7  std_ic_t2t_mou_8  std_ic_t2t_mou_9  std_ic_t2m_mou_6  \\\n",
       "0               NaN              0.00               NaN               NaN   \n",
       "1              0.00              2.35              0.00              5.90   \n",
       "2             71.29             28.69             49.44             45.18   \n",
       "3             66.44              0.00            129.84              1.33   \n",
       "4              0.00              0.86              2.31              1.93   \n",
       "\n",
       "   std_ic_t2m_mou_7  std_ic_t2m_mou_8  std_ic_t2m_mou_9  std_ic_t2f_mou_6  \\\n",
       "0               NaN              0.00               NaN               NaN   \n",
       "1              0.00             12.49             15.01              0.00   \n",
       "2            177.01            167.09            118.18             21.73   \n",
       "3             38.56              4.94             13.98              1.18   \n",
       "4              0.25              0.00              0.00              0.00   \n",
       "\n",
       "   std_ic_t2f_mou_7  std_ic_t2f_mou_8  std_ic_t2f_mou_9  std_ic_t2o_mou_6  \\\n",
       "0               NaN              0.00               NaN               NaN   \n",
       "1              0.00              0.00              0.00               0.0   \n",
       "2             58.34             43.23              3.86               0.0   \n",
       "3              0.00              0.00              0.00               0.0   \n",
       "4              0.00              0.00              0.00               0.0   \n",
       "\n",
       "   std_ic_t2o_mou_7  std_ic_t2o_mou_8  std_ic_t2o_mou_9  std_ic_mou_6  \\\n",
       "0               NaN               0.0               NaN           NaN   \n",
       "1               0.0               0.0               0.0          5.90   \n",
       "2               0.0               0.0               0.0        139.33   \n",
       "3               0.0               0.0               0.0         45.99   \n",
       "4               0.0               0.0               0.0          1.93   \n",
       "\n",
       "   std_ic_mou_7  std_ic_mou_8  std_ic_mou_9  total_ic_mou_6  total_ic_mou_7  \\\n",
       "0           NaN          0.00           NaN            0.00            0.00   \n",
       "1          0.00         14.84         15.01           26.83          104.23   \n",
       "2        306.66        239.03        171.49          370.04          519.53   \n",
       "3        105.01          4.94        143.83          280.08          216.61   \n",
       "4          0.25          0.86          2.31          216.44          198.29   \n",
       "\n",
       "   total_ic_mou_8  total_ic_mou_9  spl_ic_mou_6  spl_ic_mou_7  spl_ic_mou_8  \\\n",
       "0            5.44            0.00           NaN           NaN           0.0   \n",
       "1          423.28          188.04          0.00           0.0           0.0   \n",
       "2          395.03          517.74          0.21           0.0           0.0   \n",
       "3           53.13          305.38          0.59           0.0           0.0   \n",
       "4          338.81          205.31          0.00           0.0           0.0   \n",
       "\n",
       "   spl_ic_mou_9  isd_ic_mou_6  isd_ic_mou_7  isd_ic_mou_8  isd_ic_mou_9  \\\n",
       "0           NaN           NaN           NaN           0.0           NaN   \n",
       "1          0.00          1.83          0.00           0.0          0.00   \n",
       "2          0.45          0.00          0.85           0.0          0.01   \n",
       "3          0.55          0.00          0.00           0.0          0.00   \n",
       "4          0.18          0.00          0.00           0.0          0.00   \n",
       "\n",
       "   ic_others_6  ic_others_7  ic_others_8  ic_others_9  total_rech_num_6  \\\n",
       "0          NaN          NaN          0.0          NaN                 4   \n",
       "1         0.00         0.00          0.0         0.00                 4   \n",
       "2         0.93         3.14          0.0         0.36                 5   \n",
       "3         0.00         0.00          0.0         0.80                10   \n",
       "4         0.48         0.00          0.0         0.00                 5   \n",
       "\n",
       "   total_rech_num_7  total_rech_num_8  total_rech_num_9  total_rech_amt_6  \\\n",
       "0                 3                 2                 6               362   \n",
       "1                 9                11                 5                74   \n",
       "2                 4                 2                 7               168   \n",
       "3                11                18                14               230   \n",
       "4                 6                 3                 4               196   \n",
       "\n",
       "   total_rech_amt_7  total_rech_amt_8  total_rech_amt_9  max_rech_amt_6  \\\n",
       "0               252               252                 0             252   \n",
       "1               384               283               121              44   \n",
       "2               315               116               358              86   \n",
       "3               310               601               410              60   \n",
       "4               350               287               200              56   \n",
       "\n",
       "   max_rech_amt_7  max_rech_amt_8  max_rech_amt_9 date_of_last_rech_6  \\\n",
       "0             252             252               0           6/21/2014   \n",
       "1             154              65              50           6/29/2014   \n",
       "2             200              86             100           6/17/2014   \n",
       "3              50              50              50           6/28/2014   \n",
       "4             110             110              50           6/26/2014   \n",
       "\n",
       "  date_of_last_rech_7 date_of_last_rech_8 date_of_last_rech_9  \\\n",
       "0           7/16/2014            8/8/2014           9/28/2014   \n",
       "1           7/31/2014           8/28/2014           9/30/2014   \n",
       "2           7/24/2014           8/14/2014           9/29/2014   \n",
       "3           7/31/2014           8/31/2014           9/30/2014   \n",
       "4           7/28/2014            8/9/2014           9/28/2014   \n",
       "\n",
       "   last_day_rch_amt_6  last_day_rch_amt_7  last_day_rch_amt_8  \\\n",
       "0                 252                 252                 252   \n",
       "1                  44                  23                  30   \n",
       "2                   0                 200                  86   \n",
       "3                  30                  50                  50   \n",
       "4                  50                 110                 110   \n",
       "\n",
       "   last_day_rch_amt_9 date_of_last_rech_data_6 date_of_last_rech_data_7  \\\n",
       "0                   0                6/21/2014                7/16/2014   \n",
       "1                   0                      NaN                7/25/2014   \n",
       "2                   0                      NaN                      NaN   \n",
       "3                  30                      NaN                      NaN   \n",
       "4                  50                 6/4/2014                      NaN   \n",
       "\n",
       "  date_of_last_rech_data_8 date_of_last_rech_data_9  total_rech_data_6  \\\n",
       "0                 8/8/2014                      NaN                1.0   \n",
       "1                8/10/2014                      NaN                NaN   \n",
       "2                      NaN                9/17/2014                NaN   \n",
       "3                      NaN                      NaN                NaN   \n",
       "4                      NaN                      NaN                1.0   \n",
       "\n",
       "   total_rech_data_7  total_rech_data_8  total_rech_data_9  max_rech_data_6  \\\n",
       "0                1.0                1.0                NaN            252.0   \n",
       "1                1.0                2.0                NaN              NaN   \n",
       "2                NaN                NaN                1.0              NaN   \n",
       "3                NaN                NaN                NaN              NaN   \n",
       "4                NaN                NaN                NaN             56.0   \n",
       "\n",
       "   max_rech_data_7  max_rech_data_8  max_rech_data_9  count_rech_2g_6  \\\n",
       "0            252.0            252.0              NaN              0.0   \n",
       "1            154.0             25.0              NaN              NaN   \n",
       "2              NaN              NaN             46.0              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4              NaN              NaN              NaN              1.0   \n",
       "\n",
       "   count_rech_2g_7  count_rech_2g_8  count_rech_2g_9  count_rech_3g_6  \\\n",
       "0              0.0              0.0              NaN              1.0   \n",
       "1              1.0              2.0              NaN              NaN   \n",
       "2              NaN              NaN              1.0              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4              NaN              NaN              NaN              0.0   \n",
       "\n",
       "   count_rech_3g_7  count_rech_3g_8  count_rech_3g_9  av_rech_amt_data_6  \\\n",
       "0              1.0              1.0              NaN               252.0   \n",
       "1              0.0              0.0              NaN                 NaN   \n",
       "2              NaN              NaN              0.0                 NaN   \n",
       "3              NaN              NaN              NaN                 NaN   \n",
       "4              NaN              NaN              NaN                56.0   \n",
       "\n",
       "   av_rech_amt_data_7  av_rech_amt_data_8  av_rech_amt_data_9  vol_2g_mb_6  \\\n",
       "0               252.0               252.0                 NaN        30.13   \n",
       "1               154.0                50.0                 NaN         0.00   \n",
       "2                 NaN                 NaN                46.0         0.00   \n",
       "3                 NaN                 NaN                 NaN         0.00   \n",
       "4                 NaN                 NaN                 NaN         0.00   \n",
       "\n",
       "   vol_2g_mb_7  vol_2g_mb_8  vol_2g_mb_9  vol_3g_mb_6  vol_3g_mb_7  \\\n",
       "0         1.32         5.75          0.0        83.57       150.76   \n",
       "1       108.07       365.47          0.0         0.00         0.00   \n",
       "2         0.00         0.00          0.0         0.00         0.00   \n",
       "3         0.00         0.00          0.0         0.00         0.00   \n",
       "4         0.00         0.00          0.0         0.00         0.00   \n",
       "\n",
       "   vol_3g_mb_8  vol_3g_mb_9  arpu_3g_6  arpu_3g_7  arpu_3g_8  arpu_3g_9  \\\n",
       "0       109.61         0.00     212.17     212.17     212.17        NaN   \n",
       "1         0.00         0.00        NaN       0.00       0.00        NaN   \n",
       "2         0.00         8.42        NaN        NaN        NaN       2.84   \n",
       "3         0.00         0.00        NaN        NaN        NaN        NaN   \n",
       "4         0.00         0.00       0.00        NaN        NaN        NaN   \n",
       "\n",
       "   arpu_2g_6  arpu_2g_7  arpu_2g_8  arpu_2g_9  night_pck_user_6  \\\n",
       "0     212.17     212.17     212.17        NaN               0.0   \n",
       "1        NaN      28.61       7.60        NaN               NaN   \n",
       "2        NaN        NaN        NaN        0.0               NaN   \n",
       "3        NaN        NaN        NaN        NaN               NaN   \n",
       "4       0.00        NaN        NaN        NaN               0.0   \n",
       "\n",
       "   night_pck_user_7  night_pck_user_8  night_pck_user_9  monthly_2g_6  \\\n",
       "0               0.0               0.0               NaN             0   \n",
       "1               0.0               0.0               NaN             0   \n",
       "2               NaN               NaN               0.0             0   \n",
       "3               NaN               NaN               NaN             0   \n",
       "4               NaN               NaN               NaN             0   \n",
       "\n",
       "   monthly_2g_7  monthly_2g_8  monthly_2g_9  sachet_2g_6  sachet_2g_7  \\\n",
       "0             0             0             0            0            0   \n",
       "1             1             0             0            0            0   \n",
       "2             0             0             0            0            0   \n",
       "3             0             0             0            0            0   \n",
       "4             0             0             0            1            0   \n",
       "\n",
       "   sachet_2g_8  sachet_2g_9  monthly_3g_6  monthly_3g_7  monthly_3g_8  \\\n",
       "0            0            0             1             1             1   \n",
       "1            2            0             0             0             0   \n",
       "2            0            1             0             0             0   \n",
       "3            0            0             0             0             0   \n",
       "4            0            0             0             0             0   \n",
       "\n",
       "   monthly_3g_9  sachet_3g_6  sachet_3g_7  sachet_3g_8  sachet_3g_9  \\\n",
       "0             0            0            0            0            0   \n",
       "1             0            0            0            0            0   \n",
       "2             0            0            0            0            0   \n",
       "3             0            0            0            0            0   \n",
       "4             0            0            0            0            0   \n",
       "\n",
       "   fb_user_6  fb_user_7  fb_user_8  fb_user_9   aon  aug_vbc_3g  jul_vbc_3g  \\\n",
       "0        1.0        1.0        1.0        NaN   968        30.4         0.0   \n",
       "1        NaN        1.0        1.0        NaN  1006         0.0         0.0   \n",
       "2        NaN        NaN        NaN        1.0  1103         0.0         0.0   \n",
       "3        NaN        NaN        NaN        NaN  2491         0.0         0.0   \n",
       "4        0.0        NaN        NaN        NaN  1526         0.0         0.0   \n",
       "\n",
       "   jun_vbc_3g  sep_vbc_3g  \n",
       "0      101.20        3.58  \n",
       "1        0.00        0.00  \n",
       "2        4.17        0.00  \n",
       "3        0.00        0.00  \n",
       "4        0.00        0.00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the input data and preview\n",
    "# gpath = 'E:/01 PGD-DS/Cource-3/Module-8 - CaseStudy/'\n",
    "gpath = ''\n",
    "churn_original = pd.read_csv(gpath+'telecom_churn_data.csv')\n",
    "\n",
    "#churn_original= pd.read_csv('telecom_churn_data.csv')\n",
    "churn= churn_original.copy()\n",
    "churn.head()\n",
    "\n",
    "# Understand number of rows and columns and sneak of first 5 row\n",
    "print (churn.shape); \n",
    "churn.info()\n",
    "churn.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count_rech_2g_6             74.85\n",
       "date_of_last_rech_data_6    74.85\n",
       "count_rech_3g_6             74.85\n",
       "av_rech_amt_data_6          74.85\n",
       "max_rech_data_6             74.85\n",
       "total_rech_data_6           74.85\n",
       "arpu_3g_6                   74.85\n",
       "arpu_2g_6                   74.85\n",
       "night_pck_user_6            74.85\n",
       "fb_user_6                   74.85\n",
       "arpu_3g_7                   74.43\n",
       "count_rech_2g_7             74.43\n",
       "fb_user_7                   74.43\n",
       "count_rech_3g_7             74.43\n",
       "arpu_2g_7                   74.43\n",
       "av_rech_amt_data_7          74.43\n",
       "max_rech_data_7             74.43\n",
       "night_pck_user_7            74.43\n",
       "total_rech_data_7           74.43\n",
       "date_of_last_rech_data_7    74.43\n",
       "night_pck_user_9            74.08\n",
       "date_of_last_rech_data_9    74.08\n",
       "fb_user_9                   74.08\n",
       "arpu_2g_9                   74.08\n",
       "max_rech_data_9             74.08\n",
       "arpu_3g_9                   74.08\n",
       "total_rech_data_9           74.08\n",
       "av_rech_amt_data_9          74.08\n",
       "count_rech_3g_9             74.08\n",
       "count_rech_2g_9             74.08\n",
       "fb_user_8                   73.66\n",
       "av_rech_amt_data_8          73.66\n",
       "count_rech_3g_8             73.66\n",
       "count_rech_2g_8             73.66\n",
       "date_of_last_rech_data_8    73.66\n",
       "total_rech_data_8           73.66\n",
       "max_rech_data_8             73.66\n",
       "arpu_3g_8                   73.66\n",
       "arpu_2g_8                   73.66\n",
       "night_pck_user_8            73.66\n",
       "std_ic_t2m_mou_9             7.75\n",
       "spl_ic_mou_9                 7.75\n",
       "loc_ic_mou_9                 7.75\n",
       "isd_ic_mou_9                 7.75\n",
       "std_ic_t2o_mou_9             7.75\n",
       "loc_ic_t2f_mou_9             7.75\n",
       "ic_others_9                  7.75\n",
       "loc_og_t2f_mou_9             7.75\n",
       "loc_ic_t2m_mou_9             7.75\n",
       "loc_og_t2c_mou_9             7.75\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the % count of null so that we can impute value appropriately\n",
    "round(100*(churn.isnull().sum()/len(churn.index)), 2).sort_values(ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns which are not relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99999, 224)\n"
     ]
    }
   ],
   "source": [
    "# Dropping columns mobile and circle as they do not contribue to model building\n",
    "id_cols = ['mobile_number', 'circle_id']\n",
    "churn.drop(id_cols, axis=1, inplace=True)\n",
    "\n",
    "# Understand number of rows and columns and sneak of first 5 row\n",
    "print (churn.shape); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute missing values with zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of columns to impute missing values with zeroes\n",
    "recharge_col = ['total_rech_num_6','total_rech_num_7','total_rech_num_8','total_rech_num_9',\n",
    "                'total_rech_amt_6','total_rech_amt_7','total_rech_amt_8','total_rech_amt_9',\n",
    "                'total_rech_data_6', 'total_rech_data_7', 'total_rech_data_8','total_rech_data_9', \n",
    "                'date_of_last_rech_data_6','date_of_last_rech_data_7','date_of_last_rech_data_8','date_of_last_rech_data_9',\n",
    "                'av_rech_amt_data_6', 'av_rech_amt_data_7', 'av_rech_amt_data_8','av_rech_amt_data_9',\n",
    "                'arpu_2g_6', 'arpu_2g_7', 'arpu_2g_8','arpu_2g_9',\n",
    "                'arpu_3g_6', 'arpu_3g_7', 'arpu_3g_8','arpu_3g_9',\n",
    "                'count_rech_2g_6', 'count_rech_2g_7', 'count_rech_2g_8', 'count_rech_2g_9',\n",
    "                'count_rech_3g_6', 'count_rech_3g_7', 'count_rech_3g_8', 'count_rech_3g_9',\n",
    "                'max_rech_data_6', 'max_rech_data_7', 'max_rech_data_8', 'max_rech_data_9',\n",
    "                'fb_user_6', 'fb_user_7', 'fb_user_8',  'fb_user_9',\n",
    "                'night_pck_user_6', 'night_pck_user_7', 'night_pck_user_8','night_pck_user_9']\n",
    "# impute missing values with 0\n",
    "churn[recharge_col] = churn[recharge_col].apply(lambda x: x.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below method imputes all NaN with 0.\n",
    "churn.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sep_vbc_3g        0.0\n",
       "jun_vbc_3g        0.0\n",
       "total_og_mou_8    0.0\n",
       "total_og_mou_7    0.0\n",
       "total_og_mou_6    0.0\n",
       "og_others_9       0.0\n",
       "og_others_8       0.0\n",
       "og_others_7       0.0\n",
       "og_others_6       0.0\n",
       "spl_og_mou_9      0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the % count of null again\n",
    "round(100*(churn.isnull().sum()/len(churn.index)), 2).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In above result there are no null values in any columns.\n",
    "# we had successfully handled missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle Categorical Variables by Create Dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general method for creating dummy \n",
    "def createdummy(col, df):\n",
    "    temp = pd.get_dummies(df[col], prefix=col, drop_first = True)\n",
    "    temp_df = pd.concat([df, temp], axis = 1)\n",
    "    temp_df.drop([col], axis = 1, inplace = True)\n",
    "    return temp_df\n",
    "\n",
    "# Let’s impute missing value with  '-1' \n",
    "catg_vars = [\"night_pck_user_6\", \"night_pck_user_7\", \"night_pck_user_8\",  \"night_pck_user_9\", \n",
    "             \"fb_user_6\", \"fb_user_7\", \"fb_user_8\", \"fb_user_9\"]\n",
    "\n",
    "for var in catg_vars:\n",
    "    churn[var].fillna(value=-1, inplace=True)\n",
    "\n",
    "# Create dummy variables for all the categorial variables\n",
    "churn = createdummy('night_pck_user_6', churn)\n",
    "churn = createdummy('night_pck_user_7', churn)\n",
    "churn = createdummy('night_pck_user_8', churn)\n",
    "churn = createdummy('night_pck_user_9', churn)\n",
    "\n",
    "churn = createdummy('fb_user_6', churn)\n",
    "churn = createdummy('fb_user_7', churn)\n",
    "churn = createdummy('fb_user_8', churn)\n",
    "churn = createdummy('fb_user_9', churn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date of last call_recharge columns to datetime format\n",
    "date_last_rech_vars = [\"date_of_last_rech_6\",  \"date_of_last_rech_7\", \"date_of_last_rech_8\",\"date_of_last_rech_9\"]\n",
    "churn[date_last_rech_vars].head()\n",
    "\n",
    "# convert to datetime\n",
    "for col in date_last_rech_vars:\n",
    "    churn[col] = pd.to_datetime(churn[col])\n",
    "\n",
    "print(churn[date_last_rech_vars].info())\n",
    "churn[date_last_rech_vars].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date of last data_recharge columns to datetime format\n",
    "date_last_rech_data_vars = [\"date_of_last_rech_data_6\",  \"date_of_last_rech_data_7\", \"date_of_last_rech_data_8\",\"date_of_last_rech_data_9\"]\n",
    "churn[date_last_rech_data_vars].head()\n",
    "\n",
    "# convert to datetime\n",
    "for col in date_last_rech_data_vars:\n",
    "    churn[col] = pd.to_datetime(churn[col])\n",
    "\n",
    "print(churn[date_last_rech_data_vars].info())\n",
    "churn[date_last_rech_data_vars].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive new feature\n",
    "# Create new days columns, instead of date\n",
    "import datetime\n",
    "last_date_of_month_6 = datetime.datetime.strptime(\"30-06-2014\", \"%d-%m-%Y\")\n",
    "last_date_of_month_7 = datetime.datetime.strptime(\"31-07-2014\", \"%d-%m-%Y\")\n",
    "last_date_of_month_8 = datetime.datetime.strptime(\"31-08-2014\", \"%d-%m-%Y\")\n",
    "last_date_of_month_9 = datetime.datetime.strptime(\"31-08-2014\", \"%d-%m-%Y\")\n",
    "\n",
    "churn[\"rech_days_left_6\"]      = (last_date_of_month_6 - churn.date_of_last_rech_6).astype('timedelta64[D]')\n",
    "churn[\"rech_days_left_7\"]      = (last_date_of_month_7 - churn.date_of_last_rech_7).astype('timedelta64[D]')\n",
    "churn[\"rech_days_left_8\"]      = (last_date_of_month_8 - churn.date_of_last_rech_8).astype('timedelta64[D]')\n",
    "churn[\"rech_days_left_9\"]      = (last_date_of_month_9 - churn.date_of_last_rech_9).astype('timedelta64[D]')\n",
    "\n",
    "churn[\"rech_data_days_left_6\"]      = (last_date_of_month_6 - churn.date_of_last_rech_data_6).astype('timedelta64[D]')\n",
    "churn[\"rech_data_days_left_7\"]      = (last_date_of_month_7 - churn.date_of_last_rech_data_7).astype('timedelta64[D]')\n",
    "churn[\"rech_data_days_left_8\"]      = (last_date_of_month_8 - churn.date_of_last_rech_data_8).astype('timedelta64[D]')\n",
    "churn[\"rech_data_days_left_9\"]      = (last_date_of_month_9 - churn.date_of_last_rech_data_9).astype('timedelta64[D]')\n",
    "\n",
    "day_columns = [\"rech_days_left_6\", \"rech_days_left_7\", \"rech_days_left_8\",\"rech_days_left_9\" ,\n",
    "               \"rech_data_days_left_6\", \"rech_data_days_left_7\", \"rech_data_days_left_8\",\"rech_data_days_left_9\" ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all old date columns: add dates columns to drop_column list\n",
    "churn.drop(date_last_rech_vars, axis=1, inplace=True)\n",
    "churn.drop(date_last_rech_data_vars, axis=1, inplace=True)\n",
    "\n",
    "print(churn.shape);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the date columns which would not help to make any business recommendation.\n",
    "date_id_cols = ['last_date_of_month_6', 'last_date_of_month_7','last_date_of_month_8','last_date_of_month_9']\n",
    "churn.drop(date_id_cols, axis=1, inplace=True)\n",
    "print(churn.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns which has same value in all rows. \n",
    "# There is no variance in the values for these column.\n",
    "nunique = churn.apply(pd.Series.nunique)\n",
    "cols_to_drop = nunique[nunique == 1].index\n",
    "print(cols_to_drop)\n",
    "churn.drop(cols_to_drop, axis=1,inplace=True)\n",
    "print(churn.shape);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now all the data type is either float64 or int64 or  uint8(8).\n",
    "# We are ready for the model.\n",
    "churn.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oulier Assesment and Treatment.\n",
    "Use data distribution to find outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn.describe(percentiles=[.01,.25,.5,.75,.90,.95,.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the outlier \n",
    "# If outlier is lesser than the 1% percentile, then reset it  to 1% percentile\n",
    "# If outlier is greater than the 99% percentile, then reset it  to 99% percentile\n",
    "cont_cols = [col for col in churn.columns]\n",
    "\n",
    "for col in cont_cols:\n",
    "    percentiles = churn[col].quantile([0.01,0.99]).values\n",
    "    churn[col][churn[col] <= percentiles[0]] = percentiles[0]\n",
    "    churn[col][churn[col] >= percentiles[1]] = percentiles[1]\n",
    "    \n",
    "# Now lets look at the outliers again\n",
    "churn.describe(percentiles=[.01,.25,.5,.75,.90,.95,.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After outlier treatment Drop columns which has same value in all rows. \n",
    "# Since having a column with same values won't help in modelling.\n",
    "nunique = churn.apply(pd.Series.nunique)\n",
    "cols_to_drop = nunique[nunique == 1].index\n",
    "print(cols_to_drop)\n",
    "churn.drop(cols_to_drop, axis=1,inplace=True)\n",
    "print(churn.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original Dataframe Shape: ', churn_original.shape); \n",
    "print(\"Original Dataframe Info: \\n\"); churn_original.info(); \n",
    "print(\"Original Dataframe Nulls:\", churn_original.isnull().sum().sum()); \n",
    "\n",
    "print('Cleaned Dataframe Shape: ', churn.shape); \n",
    "print(\"Cleaned Dataframe Info: \\n\"); churn.info(); \n",
    "print(\"Cleaned Dataframe Nulls:\", churn.isnull().sum().sum());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "An appropriate set of features is used to build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive new columns to consider as a feature\n",
    "\n",
    "# We could make one recharge column for the recharge made for calls and data\n",
    "# To get total recharge made for data : We should multiple Number of times the data has been recharge \n",
    "# with the amount it has been recharged.\n",
    "# Add the recharge of call and Data to get the total recharge.\n",
    "churn[\"total_rech_data_amt_6\"] = churn[\"total_rech_data_6\"]*churn['av_rech_amt_data_6']\n",
    "churn[\"total_rech_data_amt_7\"] = churn[\"total_rech_data_7\"]*churn['av_rech_amt_data_7']\n",
    "churn[\"total_rech_data_amt_8\"] = churn[\"total_rech_data_8\"]*churn['av_rech_amt_data_8']\n",
    "churn[\"total_rech_data_amt_9\"] = churn[\"total_rech_data_9\"]*churn['av_rech_amt_data_9']\n",
    "\n",
    "churn[\"total_rech_call_and_data_amt_6\"] = churn[\"total_rech_amt_6\"] + churn[\"total_rech_data_amt_6\"]\n",
    "churn[\"total_rech_call_and_data_amt_7\"] = churn[\"total_rech_amt_7\"] + churn[\"total_rech_data_amt_7\"]\n",
    "churn[\"total_rech_call_and_data_amt_8\"] = churn[\"total_rech_amt_8\"] + churn[\"total_rech_data_amt_8\"]\n",
    "churn[\"total_rech_call_and_data_amt_9\"] = churn[\"total_rech_amt_9\"] + churn[\"total_rech_data_amt_9\"]\n",
    "\n",
    "\n",
    "# Dropping total_rech_data_* and av_rech_amt_data_*\n",
    "drop_data_columns = [\"total_rech_data_6\", \"total_rech_data_7\", \"total_rech_data_8\", \"total_rech_data_9\", \n",
    "                     'av_rech_amt_data_6', 'av_rech_amt_data_7', 'av_rech_amt_data_8', 'av_rech_amt_data_9']\n",
    "churn.drop(drop_data_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering high-value customers and tagging churned customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the total amount a customer had recharged for 6th and 7th month for both call and data.\n",
    "average_rech_amt_6_7 = (churn[\"total_rech_call_and_data_amt_6\"] + \n",
    "                      churn[\"total_rech_call_and_data_amt_7\"]) / 2.0\n",
    "\n",
    "# Find 70% percentile of the total recharge done by all customer.\n",
    "amt_70_percent = np.percentile(average_rech_amt_6_7, 70.0)\n",
    "print('70 percentile of first two months avg recharge amount: ', amt_70_percent)\n",
    "\n",
    "#Number of Customer whose has recharge is greater than the 70% percentile are High Value Customers.\n",
    "churn = churn[average_rech_amt_6_7 >= amt_70_percent]\n",
    "print('Dataframe Shape: ', churn.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the number of High Value Customers at ~30000\n",
    "# We will use this High Value Customers for further analysis and modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag churners and remove attributes of the churn phase\n",
    "# Now tag the churned customers (churn=1, else 0) based on the fourth month as follows: \n",
    "# Those who have not made any calls (either incoming or outgoing) \n",
    "# AND have not used mobile internet even once in the churn phase. \n",
    "\n",
    "# The attributes you need to use to tag churners are:\n",
    "#total_ic_mou_9\n",
    "#total_og_mou_9\n",
    "#vol_2g_mb_9\n",
    "#vol_3g_mb_9\n",
    "\n",
    "\n",
    "# Set churn to 0 on 1 based on total value of above attribute. \n",
    "# The total value being 0 means the customer haven't used any service.\n",
    "# In this excercise we are determining Churn based on usage-based\n",
    "churn_tag = churn[\"total_ic_mou_9\"] + churn[\"total_og_mou_9\"] + churn[\"vol_2g_mb_9\"] + churn[\"vol_3g_mb_9\"]\n",
    "churn[\"churned\"] = np.where(churn_tag , 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After tagging churners, remove all the attributes corresponding to the churn phase \n",
    "#(all attributes having ‘ _9’, etc. in their names) as well column marked as September\n",
    "churn = churn[churn.columns.drop(list(churn.filter(regex='_9')))]\n",
    "sep_cols = ['sep_vbc_3g']\n",
    "churn.drop(sep_cols, axis=1, inplace=True)\n",
    "\n",
    "print('Dataframe Shape after dropping columns: ', churn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA : Exploratory Analysis through plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A box plot to show how many customers has churned or not\n",
    "churn[\"churned\"].value_counts().plot('bar').set_title('churned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine Churn Rate\n",
    "y = churn['churned']\n",
    "churn_per = (sum(y)/len(y.index))*100\n",
    "print('Churn Rate of Customers: ', churn_per)\n",
    "print(churn.shape)\n",
    "\n",
    "## Churn rate is 8.13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's derive some variables. The most important feature, in this situation, \n",
    "# can be the difference between the 8th month and the previous months. \n",
    "# The difference can be in patterns such as usage difference or recharge value difference. \n",
    "# Let's calculate difference variable as the difference between 8th month and the average of 6th and 7th month.\n",
    "\n",
    "churn['arpu_diff'] = churn.arpu_8 - ((churn.arpu_6 + churn.arpu_7)/2)\n",
    "churn['onnet_mou_diff'] = churn.onnet_mou_8 - ((churn.onnet_mou_6 + churn.onnet_mou_7)/2)\n",
    "churn['offnet_mou_diff'] = churn.offnet_mou_8 - ((churn.offnet_mou_6 + churn.offnet_mou_7)/2)\n",
    "churn['roam_ic_mou_diff'] = churn.roam_ic_mou_8 - ((churn.roam_ic_mou_6 + churn.roam_ic_mou_7)/2)\n",
    "churn['roam_og_mou_diff'] = churn.roam_og_mou_8 - ((churn.roam_og_mou_6 + churn.roam_og_mou_7)/2)\n",
    "churn['loc_og_mou_diff'] = churn.loc_og_mou_8 - ((churn.loc_og_mou_6 + churn.loc_og_mou_7)/2)\n",
    "churn['std_og_mou_diff'] = churn.std_og_mou_8 - ((churn.std_og_mou_6 + churn.std_og_mou_7)/2)\n",
    "churn['isd_og_mou_diff'] = churn.isd_og_mou_8 - ((churn.isd_og_mou_6 + churn.isd_og_mou_7)/2)\n",
    "churn['spl_og_mou_diff'] = churn.spl_og_mou_8 - ((churn.spl_og_mou_6 + churn.spl_og_mou_7)/2)\n",
    "churn['total_og_mou_diff'] = churn.total_og_mou_8 - ((churn.total_og_mou_6 + churn.total_og_mou_7)/2)\n",
    "churn['loc_ic_mou_diff'] = churn.loc_ic_mou_8 - ((churn.loc_ic_mou_6 + churn.loc_ic_mou_7)/2)\n",
    "churn['std_ic_mou_diff'] = churn.std_ic_mou_8 - ((churn.std_ic_mou_6 + churn.std_ic_mou_7)/2)\n",
    "churn['isd_ic_mou_diff'] = churn.isd_ic_mou_8 - ((churn.isd_ic_mou_6 + churn.isd_ic_mou_7)/2)\n",
    "churn['spl_ic_mou_diff'] = churn.spl_ic_mou_8 - ((churn.spl_ic_mou_6 + churn.spl_ic_mou_7)/2)\n",
    "churn['total_ic_mou_diff'] = churn.total_ic_mou_8 - ((churn.total_ic_mou_6 + churn.total_ic_mou_7)/2)\n",
    "churn['total_rech_num_diff'] = churn.total_rech_num_8 - ((churn.total_rech_num_6 + churn.total_rech_num_7)/2)\n",
    "churn['total_rech_amt_diff'] = churn.total_rech_amt_8 - ((churn.total_rech_amt_6 + churn.total_rech_amt_7)/2)\n",
    "churn['max_rech_amt_diff'] = churn.max_rech_amt_8 - ((churn.max_rech_amt_6 + churn.max_rech_amt_7)/2)\n",
    "churn['total_rech_call_and_data_diff'] = churn.total_rech_call_and_data_amt_8 - ((churn.total_rech_call_and_data_amt_6 + churn.total_rech_call_and_data_amt_7)/2)\n",
    "churn['max_rech_data_diff'] = churn.max_rech_data_8 - ((churn.max_rech_data_6 + churn.max_rech_data_7)/2)\n",
    "churn['vol_2g_mb_diff'] = churn.vol_2g_mb_8 - ((churn.vol_2g_mb_6 + churn.vol_2g_mb_7)/2)\n",
    "churn['vol_3g_mb_diff'] = churn.vol_3g_mb_8 - ((churn.vol_3g_mb_6 + churn.vol_3g_mb_7)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new feature by adding all 2G, 3G Data\n",
    "# 'vol_data_mb_6', 'vol_data_mb_7', 'vol_data_mb_8'\n",
    "for i in range(6,8):\n",
    "    churn['vol_data_mb_'+str(i)] = (churn['vol_2g_mb_'+str(i)]+churn['vol_3g_mb_'+str(i)]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlate all columns with churned column to know if there are any positive and negative correlation.\n",
    "churn[churn.columns[1:]].corr()['churned'][:].sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insight and Important Churn Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could predict Customers who could Churn with +ve correlation features. \n",
    "# We can reach to these customers and give some offers and discounts to retain them.\n",
    "# rech_days_left_8 : Customers who has more days to recharge TalkTime have churned. Giving the offer early in the month will help to retain.\n",
    "# rech_data_days_left_8 : Customers who has more days to recharge DATA have churned. Giving the offer early in the month will help to retain.\n",
    "# std_og_mou_6 : Customers who did more STD outgoing calls have churned. Giving discounts to STD calls will help to retain.\n",
    "# roam_og_mou_7 : Customers who were in roaming and making outgoing calls have Churned. Giving discounts to Roaming calls will help to retain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insight about Customers who haven't churned from Columns having negative corelation\n",
    "# arpu_diff : 'Average revenue per user' Customers who were generating same revenue for 6th, 7th and 8th month have not churned.\n",
    "# total_rech_amt_diff : Customers who have been recharging same amount for 6th, 7th and 8th month have not churned.\n",
    "# total_ic_mou_8 : Customers who got high incoming calls in 8th month, have not churned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create plotting functions\n",
    "def data_type(variable):\n",
    "    if variable.dtype == np.int64 or variable.dtype == np.float64:\n",
    "        return 'numerical'\n",
    "    elif variable.dtype == 'category':\n",
    "        return 'categorical'\n",
    "    \n",
    "def univariate(variable, stats=True):\n",
    "    if data_type(variable) == 'numerical':\n",
    "        sns.distplot(variable)\n",
    "        if stats == True:\n",
    "            print(variable.describe())\n",
    "    elif data_type(variable) == 'categorical':\n",
    "        sns.countplot(variable)\n",
    "        if stats == True:\n",
    "            print(variable.value_counts())\n",
    "    else:\n",
    "        print(\"Invalid variable passed: either pass a numeric variable or a categorical vairable.\")\n",
    "\n",
    "def plot_byChurnMou(colList,calltype):\n",
    "    fig, ax = plt.subplots(figsize=(7,4))\n",
    "    df=churn.groupby(['churned'])[colList].mean().T\n",
    "    plt.plot(df)\n",
    "    ax.set_xticklabels(['Jun','Jul','Aug','Sep'])\n",
    "    ## Add legend\n",
    "    plt.legend(['Non-Churn', 'Churn'])\n",
    "    # Add titles\n",
    "    plt.title(\"Avg. \"+calltype+\" MOU  V/S Month\", loc='left', fontsize=12, fontweight=0, color='orange')\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Avg. \"+calltype+\" MOU\")\n",
    "\n",
    "def plot_byChurn(data,col):\n",
    "    # per month churn vs Non-Churn\n",
    "    fig, ax = plt.subplots(figsize=(7,4))\n",
    "    colList=list(data.filter(regex=(col)).columns)\n",
    "    colList = colList[:3]\n",
    "    plt.plot(churn.groupby('churned')[colList].mean().T)\n",
    "    ax.set_xticklabels(['Jun','Jul','Aug','Sep'])\n",
    "    ## Add legend\n",
    "    plt.legend(['Non-Churn', 'Churn'])\n",
    "    # Add titles\n",
    "    plt.title( str(col) +\" V/S Month\", loc='left', fontsize=12, fontweight=0, color='orange')\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(col)\n",
    "    plt.show()\n",
    "    # Numeric stats for per month churn vs Non-Churn\n",
    "    return churn.groupby('churned')[colList].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate(churn.rech_days_left_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate(churn.std_og_mou_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate(churn.roam_og_mou_7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the total_rech_data_* to see the distribution\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.subplot(2,2,1)\n",
    "sns.distplot(churn.total_rech_call_and_data_amt_6)\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "sns.distplot(churn.total_rech_call_and_data_amt_7)\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "sns.distplot(churn.total_rech_call_and_data_amt_8)\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "sns.distplot(churn.aon)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['total_rech_call_and_data_amt_6', 'total_rech_call_and_data_amt_7', 'total_rech_call_and_data_amt_8']\n",
    "churn[numerical_features].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn[numerical_features].hist(bins=30, figsize=(10, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review two columns with churn as target\n",
    "cont_cols = [col for col in churn.columns ]\n",
    "for col in cont_cols:\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    sns.barplot(x='churned', y=col, data=churn)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_col = ['total_ic_mou_6','total_ic_mou_7','total_ic_mou_8']\n",
    "og_col = ['total_og_mou_6','total_og_mou_7','total_og_mou_8']\n",
    "plot_byChurnMou(ic_col,'Incoming')\n",
    "plot_byChurnMou(og_col,'Outgoing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above plot we could determine\n",
    "- Customers who churned, has a drop in incoming and outgoing calls between Jun, Jul and August.\n",
    "\n",
    "- Customers who did not churn, remained almost flat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_byChurn(churn,'vol_data_mb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above plot we could determine that\n",
    "- The volume of data mb used drops significantly for churners from month Jul(6) to Aug(7).\n",
    "- While it remains almost consistent for the non-churners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn2 = churn.copy()\n",
    "churn2.drop(['churned'], axis=1)\n",
    "\n",
    "\n",
    "# Let's see the correlation matrix \n",
    "plt.figure(figsize = (20,20))        # Size of the figure\n",
    "sns.heatmap(churn2.corr())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = churn2.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns whose correlation greater than 0.80\n",
    "high_corr_features = [column for column in upper.columns if any(upper[column] > 0.80)]\n",
    "\n",
    "print(\"Highly Correlated Features :{}\\n\\n{}\".format(len(high_corr_features), high_corr_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 51 highly correlated features (> 80%) found in the data set.\n",
    "We are not dropping these columns manually rather using feature reduction methods to do the job. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2 : Modelling through different methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 : Logistic regression\n",
    "Logistic Regression is a Machine Learning algorithm which is used for the classification problems, it is a predictive analysis algorithm and based on the concept of probability.\n",
    "\n",
    "Logistic regression is basically a supervised classification algorithm. \n",
    "In a classification problem, the target variable (or output), y, can take only discrete values for given set of features(or inputs), X.\n",
    "\n",
    "Logistic regression becomes a classification technique only when a decision threshold is brought into the picture. The setting of the threshold value is a very important aspect of Logistic regression and is dependent on the classification problem itself.\n",
    "\n",
    "The decision for the value of the threshold value is majorly affected by the values of precision and recall. Ideally, we want both precision and recall to be 1, but this seldom is the case. \n",
    "\n",
    "In our case Customer Churn is the Target Variable and all other columns are features/input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting feature variable to X\n",
    "X = churn.drop([\"churned\"], axis=1)\n",
    "# Putting response variable to y\n",
    "y = churn[\"churned\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(X=train_x, y=train_y)\n",
    "\n",
    "test_y_pred = logisticRegr.predict(test_x)\n",
    "confusion_matrix = confusion_matrix(test_y, test_y_pred)\n",
    "print('Intercept: ' + str(logisticRegr.intercept_))\n",
    "print('Regression: ' + str(logisticRegr.coef_))\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logisticRegr.score(test_x, test_y)))\n",
    "print(classification_report(test_y, test_y_pred))\n",
    "\n",
    "confusion_matrix_df = pd.DataFrame(confusion_matrix, ('No churn', 'Churn'), ('No churn', 'Churn'))\n",
    "heatmap = sns.heatmap(confusion_matrix_df, annot=True, annot_kws={\"size\": 20}, fmt=\"d\")\n",
    "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize = 14)\n",
    "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize = 14)\n",
    "plt.ylabel('True label', fontsize = 14)\n",
    "plt.xlabel('Predicted label', fontsize = 14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of logistic regression classifier on test set: 0.93\n",
    "\n",
    "But the Precision and Recall for positive case seems to be low. Which  suggests our data set may be imbalanced.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It is also important to look at the distribution of how many customers churn. \n",
    "# If 95% of customers don’t churn, we can achieve 95% accuracy by building a model \n",
    "# that simply predicts that all customers won’t churn. \n",
    "# But this isn’t a very useful model, because it will never tell us when a customer will churn, \n",
    "# which is what we are really interested in.\n",
    "churn['churned'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class for churn is only around 8% of the total population of samples. \n",
    "\n",
    "There is a real risk that a model trained on this data may only make too many predictions in favour of the majority class. There are a number of techniques for handling imbalanced classes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Class Imbalance by up-sampling minority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Up-sampling the minority class\n",
    "# To balance the data set, we can randomly duplicate observations from the minority class. \n",
    "# This is also known as re sampling with replacement:\n",
    "from sklearn.utils import resample\n",
    "\n",
    "data_majority = churn[churn['churned']==0]\n",
    "data_minority = churn[churn['churned']==1]\n",
    "\n",
    "data_minority_upsampled = resample(data_minority,\n",
    "replace=True,\n",
    "n_samples=27560, #same number of samples as majority class\n",
    "random_state=1) #set the seed for random resampling\n",
    "\n",
    "# Combine resampled results\n",
    "data_upsampled = pd.concat([data_majority, data_minority_upsampled])\n",
    "\n",
    "data_upsampled['churned'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have a 1:1 ratio for our classes, let’s train another logistic regression model:\n",
    "train, test = train_test_split(data_upsampled, test_size = 0.3)\n",
    "\n",
    "train_y_upsampled = train['churned']\n",
    "test_y_upsampled = test['churned']\n",
    "\n",
    "train_x_upsampled = train\n",
    "train_x_upsampled.pop('churned')\n",
    "test_x_upsampled = test\n",
    "test_x_upsampled.pop('churned')\n",
    "\n",
    "logisticRegr_balanced = LogisticRegression()\n",
    "logisticRegr_balanced.fit(X=train_x_upsampled, y=train_y_upsampled)\n",
    "\n",
    "test_y_pred_balanced = logisticRegr_balanced.predict(test_x_upsampled)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logisticRegr_balanced.score(test_x_upsampled, test_y_upsampled)))\n",
    "print(classification_report(test_y_upsampled, test_y_pred_balanced))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall accuracy of the model has decreased from 93% to 83%\n",
    "\n",
    "But the precision and recall scores for predicting a churn have improved to 83%. \n",
    "\n",
    "There are a number of other ways to deal with imbalanced classes, like below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a different performance metric\n",
    "# Area Under ROC Curve (AUROC) represents the likelihood of a model distinguishing observations between two classes. \n",
    "# In very simple terms, AUROC gives a single measure of how a model’s true positive rate and false positive rate change with different threshold values. \n",
    "# The closer a model’s AUROC score is to 1, the better it is. \n",
    "# To calculate AUROC, we need the predicted class probabilities:\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Get class probabilities for both models\n",
    "test_y_prob = logisticRegr.predict_proba(test_x)\n",
    "test_y_prob_balanced = logisticRegr_balanced.predict_proba(test_x_upsampled)\n",
    "\n",
    "# We only need the probabilities for the positive class\n",
    "test_y_prob = [p[1] for p in test_y_prob]\n",
    "test_y_prob_balanced = [p[1] for p in test_y_prob_balanced]\n",
    "\n",
    "print('Unbalanced model AUROC: ' + str(roc_auc_score(test_y, test_y_prob)))\n",
    "print('Balanced model AUROC: ' + str(roc_auc_score(test_y_upsampled, test_y_prob_balanced)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUROC score for Balanced model is closer to 1. Hence we should prefer the Balanced model for Prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 : Tree-based algorithms\n",
    " - Decision Trees\n",
    " - Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using tree-based algorithms such as decision trees or random forests can result in good models for \n",
    "unbalanced datasets. If the minority class exists in one area of the feature space, a tree will be able \n",
    "to separate the class into a single node.\n",
    "For example, if 99% of customers who stream movies tend to churn, then a tree-based algorithm will likely pick this up. \n",
    "We will look at the results for two of these algorithms in the next section.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Trees\n",
    "# A decision tree is a supervised learning method that makes a prediction by learning simple decision rules from the explanatory variables. \n",
    "# Decision trees have the following advantages:\n",
    "\n",
    "#Trees can be visualised, which makes them easy to interpret\n",
    "#They can handle numerical and categorical data\n",
    "#We can easily validate the model using statistical tests\n",
    "#The downsides to decision trees:\n",
    "\n",
    "#Decision trees are very prone to overfitting the training data, and often do not generalise well\n",
    "#Small variations in the training data can cause a completely different tree to be generated\n",
    "#Decision tree learning algorithms are based on heuristic algorithms like the greedy algorithm, which make locally optimal decisions at each node. \n",
    "#These algorithms cannot guarantee a globally optimal decision tree\n",
    "#Despite their downsides, decision trees can be a good starting point for developing predictive models that generalise better, like random forests.\n",
    "\n",
    "from sklearn import tree\n",
    "from IPython.display import Image  \n",
    "import graphviz \n",
    "import pydotplus\n",
    "from sklearn.externals.six import StringIO  \n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "\n",
    "# Create each decision tree (pruned and unpruned)\n",
    "decisionTree_unpruned = tree.DecisionTreeClassifier()\n",
    "decisionTree = tree.DecisionTreeClassifier(max_depth = 4)\n",
    "\n",
    "# Fit each tree to our training data\n",
    "decisionTree_unpruned = decisionTree_unpruned.fit(X=train_x, y=train_y)\n",
    "decisionTree = decisionTree.fit(X=train_x, y=train_y)\n",
    "\n",
    "dot_data = StringIO()\n",
    "export_graphviz(decisionTree, out_file=dot_data,  \n",
    "                feature_names = list(train_x.columns.values),  \n",
    "                class_names = ['No churn', 'Churn'],\n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_pred_dt = decisionTree.predict(test_x)\n",
    "\n",
    "print(classification_report(test_y, test_y_pred_dt))\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print('Accuracy of decision tree classifier on test set: {:.2f}'.format(decisionTree.score(test_x, test_y)))\n",
    "print(confusion_matrix(test_y,test_y_pred_dt))\n",
    "print(accuracy_score(test_y,test_y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have set the maximum depth of the tree to 4 in the above example. \n",
    "# The other variable controlling the size of the tree is ‘min_samples_leaf’, \n",
    "# which specifies the minimum number of samples required to split an internal node. \n",
    "# The default depth and minimum samples per leaf are set to unlimited, which leads to fully grown and unpruned trees,\n",
    "# like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from IPython.display import Image  \n",
    "import graphviz \n",
    "import pydotplus\n",
    "from sklearn.externals.six import StringIO  \n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "\n",
    "# Create each decision tree (pruned and unpruned)\n",
    "decisionTree_unpruned = tree.DecisionTreeClassifier()\n",
    "decisionTree = tree.DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "# Fit each tree to our training data\n",
    "decisionTree_unpruned = decisionTree_unpruned.fit(X=train_x, y=train_y)\n",
    "decisionTree = decisionTree.fit(X=train_x, y=train_y)\n",
    "\n",
    "dot_data = StringIO()\n",
    "export_graphviz(decisionTree, out_file=dot_data,  \n",
    "                feature_names = list(train_x.columns.values),  \n",
    "                class_names = ['No churn', 'Churn'],\n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An unpruned tree is effectively trying to sort every training example \n",
    "# ‘perfectly’ into its own leaf. We will get very good ‘accuracy’ \n",
    "# when testing against the training set, but it is likely that the \n",
    "# model is over fitted.\n",
    "# Let’s see what kind of accuracy each of the trees get on test and training sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_pred_dt = decisionTree.predict(test_x)\n",
    "print('Accuracy of decision tree classifier on test set: {:.2f}'.format(decisionTree.score(test_x, test_y)))\n",
    "print(classification_report(test_y, test_y_pred_dt))\n",
    "print(confusion_matrix(test_y,test_y_pred_dt))\n",
    "print(accuracy_score(test_y,test_y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3 : Random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forests are an ensemble learning method, where the results from multiple decision trees are\n",
    "# combined to make a final prediction. For example, a random forest may be made up of 10 decision trees, \n",
    "# 7 of which make a prediction for ‘churn’ and 3 of which make a prediction for ‘no churn’. \n",
    "# The final prediction for the forest will be ‘churn’.\n",
    "# Tree ensembles have become very popular due to their impressive performance on many real world problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "randomForest = RandomForestClassifier()\n",
    "randomForest.fit(train_x, train_y)\n",
    "test_y_pred_dt = randomForest.predict(test_x)\n",
    "\n",
    "print('Accuracy of random forest classifier on test set: {:.2f}'.format(randomForest.score(test_x, test_y)))\n",
    "\n",
    "print(classification_report(test_y, test_y_pred_dt))\n",
    "print(confusion_matrix(test_y,test_y_pred_dt))\n",
    "print(accuracy_score(test_y,test_y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,40))\n",
    "feat_importances = pd.Series(randomForest.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(len(X.columns)).sort_values().plot(kind='barh', align='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graph above suggest that the top features ranked in order of importance as produced by our RandomForest implementation are the features that belong to month 8 i.e., the action month. \n",
    "\n",
    "Hence, it is clear that what happens in the action phase has a direct impact on the customer churn of high value customers. Specifically, these features are as follows:\n",
    "\n",
    "total_ic_mou_8 -> Total incoming minutes of usage in month 8\n",
    "\n",
    "loc_ic_mou_8 -> local incoming minutes of usage in month 8\n",
    "\n",
    "total_rech_call_and_data_amt_8 -> Total (talk time and data) recharge amount in month 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4 : PCA - Dimensionality reduction\n",
    "\n",
    "The main idea of principal component analysis (PCA) is to reduce the dimensionality of a data set consisting of many variables correlated with each other, either heavily or lightly, while retaining the variation present in the dataset, up to the maximum extent. The same is done by transforming the variables to a new set of variables, which are known as the principal components (or simply, the PCs) and are orthogonal, ordered such that the retention of variation present in the original variables decreases as we move down in the order. So, in this way, the 1st principal component retains maximum variation that was present in the original components. The principal components are the eigenvectors of a covariance matrix, and hence they are orthogonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(random_state=100)\n",
    "pca.fit(train_x)\n",
    "df_train_pca = pca.fit_transform(train_x)\n",
    "print(df_train_pca.shape)\n",
    "df_test_pca = pca.transform(test_x)\n",
    "print(df_test_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model using the selected variables\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "logsk = LogisticRegression(C=1e9)\n",
    "logsk.fit(df_train_pca, train_y)\n",
    "\n",
    "# Predicted probabilities\n",
    "y_pred = logsk.predict(df_test_pca)\n",
    "# Converting y_pred to a dataframe which is an array\n",
    "y_pred_df = pd.DataFrame(y_pred)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Printing confusion matrix\n",
    "print(confusion_matrix(test_y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LogisticRegression accuracy with PCA: \",accuracy_score(test_y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = list(X.columns)\n",
    "pcs_df = pd.DataFrame({'PC1':pca.components_[0],'PC2':pca.components_[1], 'PC3':pca.components_[2],'Feature':colnames})\n",
    "pcs_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the screeplot - plotting the cumulative variance against the number of components\n",
    "%matplotlib inline\n",
    "fig = plt.figure(figsize = (12,8))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply logistic regression with 3 columns (90% explained variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca3 = PCA(n_components=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pca3 = pca3.fit_transform(train_x)\n",
    "print(df_train_pca3.shape)\n",
    "df_test_pca3 = pca3.transform(test_x)\n",
    "print(df_test_pca3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's run the model using the selected variables\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "logsk1 = LogisticRegression(C=1e9)\n",
    "logsk1.fit(df_train_pca3, train_y)\n",
    "\n",
    "# Predicted probabilities\n",
    "y_pred3 = logsk1.predict(df_test_pca3)\n",
    "# Converting y_pred to a dataframe which is an array\n",
    "y_pred_df = pd.DataFrame(y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing confusion matrix\n",
    "print(confusion_matrix(test_y,y_pred3))\n",
    "print(\"LogisticRegression accuracy with PCA: \",accuracy_score(test_y,y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "91% accuracy with default PCA\n",
    "90% variance can be explained with first 3 columns and still maintain 92% accuracy\n",
    "Key Features are arpu_6, arpu_7, arpu_8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying important churn indicators ,  insights and Business recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could predict Customers who could Churn with +ve correlation features. \n",
    "We can reach to these customers and give some offers and discounts to retain them.\n",
    " - rech_days_left_8 : Customers who has more days to recharge TalkTime have churned. Giving the offer early in the month will help to retain.\n",
    " - rech_data_days_left_8 : Customers who has more days to recharge DATA have churned. Giving the offer early in the month will help to retain.\n",
    " - std_og_mou_6 : Customers who did more STD outgoing calls have churned. Giving discounts to STD calls will help to retain.\n",
    " - roam_og_mou_7 : Customers who were in roaming and making outgoing calls have Churned. Giving discounts to Roaming calls will help to retain.\n",
    " - arpu_6, arpu_7, arpu_8 : Average Revenue Per User : Customers who haven't generated revenue are most would Churn.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insight about Customers who haven't churned from Columns having negative corelation\n",
    " - arpu_diff : 'Average revenue per user' Customers who were generating same revenue for 6th, 7th and 8th month have not churned.\n",
    " - total_rech_amt_diff : Customers who have been recharging same amount for 6th, 7th and 8th month have not churned.\n",
    " - total_ic_mou_8 : Customers who got high incoming calls in 8th month, have not churned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection of Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of logistic regression  (unbalanced) : 93%\n",
    "\n",
    "Accuracy of logistic regression  (balanced) : 83%\n",
    "\n",
    "Accuracy of decision Tree : 91%\n",
    "\n",
    "Accuracy of random forest : 94%\n",
    "\n",
    "Accuracy of PCA : 91% \n",
    "\n",
    "Accuracy of PCA (with first three columns) : 92% \n",
    "\n",
    "Clearly Random Forest Model is much better among all other Classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
